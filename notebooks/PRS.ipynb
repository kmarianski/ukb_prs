{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = pd.read_table('DYX_auto.sscore')\n",
    "prs.rename(columns={'SCORE1_AVG': 'PRS'}, inplace=True)\n",
    "ukb = pd.read_csv(\"merged.csv\")\n",
    "ukb['status'] = ukb.loc[:, 'dosage'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the main histogram\n",
    "n, bins, patches = plt.hist(prs['SCORE1_AVG'], bins=30, edgecolor='black', alpha=0.7, color='#9cff33')\n",
    "\n",
    "# Calculate the 10th and 90th percentiles\n",
    "p10 = np.percentile(prs['SCORE1_AVG'], 10)\n",
    "p90 = np.percentile(prs['SCORE1_AVG'], 90)\n",
    "\n",
    "# Add vertical lines with different colors and styles\n",
    "plt.axvline(x=p10, color='red', linestyle='--', label='10th percentile')\n",
    "plt.axvline(x=p90, color='blue', linestyle='--', label='90th percentile')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of PRS')\n",
    "plt.xlabel('PRS')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('./figures/prs_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33803ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = {\n",
    "    # General\n",
    "    'eid': 'IID', \n",
    "    'p31': 'sex',\n",
    "    'p21022': 'Age at recruitment',\n",
    "    'p22189': 'TDI',\n",
    "    'p22006': 'Genetic ethnic grouping',\n",
    "    # Category 120: Numeric memory (Cognitive function online)\n",
    "    '20240': 'Maximum digits remembered correctly',\n",
    "    # Category 1358: Broken letter recognition\n",
    "    '20139': 'Number of letters correctly identified',\n",
    "       \n",
    "    # Category 100027: Fluid intelligence / reasoning\n",
    "    '20016': 'Fluid intelligence score',\n",
    "    \n",
    "    # Category 100029: Numeric memory\n",
    "    '4282': 'Maximum digits remembered correctly',\n",
    "\n",
    "    # Category 100032: Reaction time\n",
    "    '20023': 'Mean time to correctly identify matches',\n",
    "\n",
    "    # Category 503: Tower rearranging\n",
    "    '21004': 'Number of puzzles correct',\n",
    "    # Category 504: Picture vocabulary\n",
    "    '26302': 'Specific cognitive ability (AS)',\n",
    "    '6364': 'Vocabulary level',\n",
    "    # Category 501: Matrix pattern completion\n",
    "    '6373': 'Number of puzzles correctly solved',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_means(covariates, df=ukb):\n",
    "    means = {}\n",
    "    for description in covariates.values():\n",
    "        if description not in ('IID', 'sex', 'TDI'):\n",
    "            base_col_name = description.replace(' ', '_')\n",
    "            temp_cols = df.columns[df.columns.str.startswith(base_col_name)]\n",
    "            mean = df[temp_cols].mean(axis=1)\n",
    "            means[f\"mean_{base_col_name}\"] = mean\n",
    "    return means\n",
    "\n",
    "merged_means = pd.concat([ukb, pd.DataFrame(calculate_means(covariates))], axis=1)\n",
    "\n",
    "descriptive = ['IID', 'status', 'sex', 'TDI']\n",
    "mean_cols = list(merged_means.columns[merged_means.columns.str.startswith('mean')])\n",
    "cols = descriptive + mean_cols\n",
    "ukb_means = merged_means[cols].dropna(axis=1, how='all')\n",
    "\n",
    "df = ukb_means.merge(prs[['IID', 'PRS']], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"Number of word pairs correctly associated\", \n",
    "          \"Maximum digits remembered correctly\", \n",
    "          \"Number of letters correctly identified\"]\n",
    "\n",
    "dfs = {}\n",
    "for field in fields:\n",
    "    \n",
    "\n",
    "    phenotype = 'mean_' + field.replace(' ', '_')\n",
    "\n",
    "    ukb_means = merged_means[cols].dropna(axis=1, how='all')\n",
    "    df = ukb_means[['IID', 'status', f'{phenotype}']].merge(prs[['IID', 'PRS']], how='inner')\n",
    "\n",
    "    p10 = np.percentile(df['PRS'], 10)\n",
    "    p90 = np.percentile(df['PRS'], 90)\n",
    "\n",
    "    def calculate_prs_percentile(x):\n",
    "        if x >= p90:\n",
    "            return 'top_10%'\n",
    "        elif x <= p10:\n",
    "            return 'bottom_10%'\n",
    "        else:\n",
    "            return 'middle_80%'\n",
    "\n",
    "    df['PRS_percentile'] = df['PRS'].apply(calculate_prs_percentile)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    df_filtered = df[df['PRS_percentile'].isin(['top_10%', 'bottom_10%'])].copy()\n",
    "\n",
    "    df_filtered['PRS_percentile'] = df_filtered['PRS_percentile'].astype('category')\n",
    "    df_filtered['status'] = df_filtered['status'].astype('category')\n",
    "\n",
    "    print(df_filtered.groupby(['PRS_percentile', 'status']).size())\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    model = ols(\n",
    "        f\"{phenotype} ~ C(PRS_percentile) * C(status)\",\n",
    "        data=df_filtered\n",
    "    ).fit()\n",
    "    \n",
    "    print(f\"{field}:\")\n",
    "    anova_results = sm.stats.anova_lm(model, typ=2)\n",
    "    dfs[f'{field}'] = anova_results\n",
    "    print(anova_results)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b07635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_anova(phenotype, df):\n",
    "    model = ols(\n",
    "        f\"{phenotype} ~ C(PRS_percentile) * C(status)\",\n",
    "        data=df\n",
    "    ).fit()\n",
    "    anova_results = sm.stats.anova_lm(model, typ=2)\n",
    "    return anova_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d12073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
